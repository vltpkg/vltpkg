name: Baseline Benchmarks

on:
  push:
    branches: main

jobs:
  benchmark_base_branch:
    name: Continuous Benchmarking with Bencher
    runs-on: ubuntu-latest
    strategy:
      matrix:
        fixture: ["vue"]
        variation: ["cache-lockfile", "cache-lockfile-node-modules", "clean", "lockfile"]
    env:
      BENCH_WARMUP: '2'
      BENCH_RUNS: '10'
    steps:
      - uses: actions/checkout@v4

      - uses: pnpm/action-setup@v4
        with:
          run_install: false

      - name: Install Node
        uses: actions/setup-node@v4
        with:
          node-version: '24'
          cache: pnpm
          check-latest: true

      - name: Install Dependencies
        run: pnpm install --filter="./src/*" --ignore-scripts

      - name: Setup vlt binaries
        run: echo "$(pwd)/scripts/bins" >> $GITHUB_PATH

      - name: Install & Setup Tools
        run: |
          bash ./infra/cli-benchmarks/scripts/setup.sh

      - name: Run Benchmarks variations
        run: |
          bash ./infra/cli-benchmarks/scripts/benchmark.sh ${{ matrix.fixture }} ${{ matrix.variation }}

      - name: Upload Benchmark Results
        uses: actions/upload-artifact@v4
        with:
          name: results-${{ matrix.fixture }}-${{ matrix.variation }}
          path: ./results/${{ matrix.fixture }}/${{ matrix.variation }}/

  consolidate:
    name: Consolidate Benchmark Results
    needs: [benchmark_base_branch]
    permissions:
      checks: write
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Download Results
        uses: actions/download-artifact@v4
        with:
          path: results
          pattern: results-*

      - name: Consolidate benchmarks
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');

            // Define fixture and variation values from the strategy matrix
            const fixtures = ["vue"];
            const variations = ["cache-lockfile", "cache-lockfile-node-modules", "clean", "lockfile"];

            const consolidatedResults = {
              results: []
            };

            // Read and consolidate benchmark results
            for (const fixture of fixtures) {
              for (const variation of variations) {
                const benchmarkPath = path.join('results', `results-${fixture}-${variation}`, 'benchmarks.json');

                try {
                  console.log(`Reading benchmark file: ${benchmarkPath}`);
                  const benchmarkData = JSON.parse(fs.readFileSync(benchmarkPath, 'utf8'));

                  // Take the first entry from the results array
                  if (benchmarkData.results && benchmarkData.results.length > 0) {
                    consolidatedResults.results.push(benchmarkData.results[0]);
                    console.log(`Added result for ${fixture}-${variation}: ${benchmarkData.results[0].command}`);
                  } else {
                    console.warn(`No results found in ${benchmarkPath}`);
                  }
                } catch (error) {
                  console.error(`Failed to read ${benchmarkPath}: ${error.message}`);
                }
              }
            }

            // Save consolidated results
            const outputPath = 'benchmarks.json';
            fs.writeFileSync(outputPath, JSON.stringify(consolidatedResults, null, 2));
            console.log(`Consolidated ${consolidatedResults.results.length} benchmark results to ${outputPath}`);

      - uses: bencherdev/bencher@main
      - name: Track base branch benchmarks with Bencher
        run: |
          bencher run \
          --project vltpkg-monorepo \
          --token '${{ secrets.BENCHER_API_TOKEN }}' \
          --branch main \
          --hash "${{ github.sha }}" \
          --testbed ubuntu-latest \
          --threshold-measure latency \
          --threshold-test percentage \
          --threshold-min-sample-size 7 \
          --threshold-max-sample-size 10 \
          --threshold-upper-boundary 0.10 \
          --thresholds-reset \
          --adapter shell_hyperfine \
          --github-actions '${{ secrets.GITHUB_TOKEN }}' \
          --file "benchmarks.json"
